# -*- coding: utf-8 -*-
"""HousingPricesAnalytics.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1G3qPQFSLp_-p61OJknywspqhGxcBAPjf

# Data Collecting
"""

!pip install kaggle

from google.colab import files
files.upload()

!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json
!ls ~/.kaggle

!kaggle datasets download -d yasserh/housing-prices-dataset

!mkdir data
!unzip housing-prices-dataset.zip -d data
!ls data

"""# Data Understanding"""

import pandas as pd

df = pd.read_csv('data/Housing.csv')
df

df.info()

df.describe()

df.isnull().sum()

"""# Data Visualization

Correlation of price with other features
"""

categorical_vars = ['mainroad', 'guestroom', 'basement', 'hotwaterheating', 'airconditioning', 'parking', 'prefarea', 'furnishingstatus']
for var in categorical_vars:
    plt.figure(figsize=(10, 6))
    sns.boxplot(x=var, y='price', data=df)
    plt.title(f'Boxplot of Price by {var}')
    plt.show()

"""Correlation Matrix > Price highest correlation with area"""

corr_matrix = df.corr()
plt.figure(figsize=(10, 8))
sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt=".2f")
plt.title('Correlation Heatmap')
plt.show()

"""Violin Plot Prices with Stories"""

plt.figure(figsize=(12, 6))
sns.violinplot(x='stories', y='price', data=df)
plt.title('Violin Plot of Stories vs. Price')
plt.xlabel('Number of Stories')
plt.ylabel('Price')
plt.show()

binary_vars = ['mainroad', 'guestroom', 'basement', 'hotwaterheating', 'airconditioning', 'prefarea']
for var in binary_vars:
    plt.figure(figsize=(8, 5))
    sns.countplot(x=var, data=df)
    plt.title(f'Countplot of {var}')
    plt.show()

plt.figure(figsize=(10, 6))
sns.countplot(x='furnishingstatus', data=df)
plt.title('Countplot of Furnishing Status')
plt.show()

"""Price Distribution"""

plt.figure(figsize=(10, 6))
sns.histplot(df['price'], bins=30, kde=True)
plt.title('Distribution of Price')
plt.xlabel('Price')
plt.ylabel('Frequency')
plt.show()

"""Scatterplot between area and price"""

plt.figure(figsize=(10, 6))
sns.scatterplot(x='area', y='price', data=df)
plt.title('Scatterplot of Area vs. Price')
plt.xlabel('Area')
plt.ylabel('Price')
plt.show()

plt.figure(figsize=(12, 6))
sns.barplot(x='bedrooms', y='price', hue='bathrooms', data=df)
plt.title('Average Price Based on Bedrooms and Bathrooms')
plt.xlabel('Bedrooms')
plt.ylabel('Average Price')
plt.show()

fig, axes = plt.subplots(1, 2, figsize=(14, 5))

sns.countplot(x='parking', data=df, ax=axes[0])
axes[0].set_title('Countplot of Parking Availability')

sns.countplot(x='airconditioning', data=df, ax=axes[1])
axes[1].set_title('Countplot of Air Conditioning Availability')

plt.show()

import seaborn as sns
import matplotlib.pyplot as plt

numeric_vars = ['price', 'area', 'bedrooms', 'bathrooms', 'stories']
sns.pairplot(df[numeric_vars])
plt.show()

import matplotlib.pyplot as plt

furnishing_counts = df['furnishingstatus'].value_counts()

# Plot a pie chart
plt.figure(figsize=(8, 8))
plt.pie(furnishing_counts, labels=furnishing_counts.index, autopct='%1.1f%%', startangle=90, colors=['skyblue', 'lightcoral', 'lightgreen'])
plt.title('Distribution of Furnishing Status')
plt.show()

"""# Remove Outlier Data"""

Q1 = df['price'].quantile(0.25)
Q3 = df['price'].quantile(0.75)
IQR = Q3 - Q1


outliers = (df['price'] < Q1 - 1.5 * IQR) | (df['price'] > Q3 + 1.5 * IQR)


df_cleaned = df[~outliers]


print("Original DataFrame shape:", df.shape)
print("Cleaned DataFrame shape:", df_cleaned.shape)

import seaborn as sns
import matplotlib.pyplot as plt

plt.figure(figsize=(8, 6))
sns.boxplot(x=df_cleaned['price'])
plt.title('Boxplot of Price (After Outlier Removal for price)')
plt.show()

Q1_area = df_cleaned['area'].quantile(0.25)
Q3_area = df_cleaned['area'].quantile(0.75)
IQR_area = Q3_area - Q1_area

outliers_area = (df_cleaned['area'] < Q1_area - 1.5 * IQR_area) | (df_cleaned['area'] > Q3_area + 1.5 * IQR_area)


df_cleaned_area = df_cleaned[~outliers_area]


print("Original DataFrame shape:", df_cleaned.shape)
print("Cleaned DataFrame shape (based on 'area'):", df_cleaned_area.shape)

import seaborn as sns
import matplotlib.pyplot as plt

plt.figure(figsize=(8, 6))
sns.boxplot(x=df_cleaned_area['area'])
plt.title('Boxplot of Price (After Outlier Removal for Area)')
plt.show()

df_cleaned_area

"""Cat Plot"""

import seaborn as sns
import matplotlib.pyplot as plt


selected_columns = ['bedrooms', 'bathrooms', 'price']
df_subset = df_cleaned_area[selected_columns]

sns.catplot(x='bedrooms', y='price', hue='bathrooms', data=df_subset, kind='point')
plt.title('Cat Plot of Bedrooms vs. Price (Grouped by Bathrooms)')
plt.show()

import seaborn as sns
import matplotlib.pyplot as plt


cat_features = df_cleaned_area.select_dtypes(include='object').columns.to_list()

for col in cat_features:
    plt.figure(figsize=(15, 5))
    sns.catplot(x=col, y="price", kind="bar", dodge=False, height=4, aspect=3, data=df_cleaned_area, palette="Set3")
    plt.title("Average Price Relative to {}".format(col))
    plt.show()

"""# Data Preparation

## One Hot Encoding
"""

cat_columns = ['mainroad', 'guestroom', 'basement', 'hotwaterheating', 'airconditioning', 'parking', 'prefarea', 'furnishingstatus']

df_encoded = pd.get_dummies(df_cleaned_area, columns=cat_columns, drop_first=True)

df_encoded

"""## Data Normalization"""

from sklearn.preprocessing import MinMaxScaler

scaler = MinMaxScaler()
numerical_list = ["area", "bedrooms", "price"]
df_encoded[numerical_list] = scaler.fit_transform(df_encoded[numerical_list])
df_encoded

"""## Split the Data"""

from sklearn.model_selection import train_test_split

np.random.seed(0)

X = df_encoded.drop(["price"],axis =1)
y = df_encoded["price"]
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state=123)

print(f'Total # of sample in whole dataset: {len(X)}')
print(f'Total # of sample in train dataset: {len(X_train)}')
print(f'Total # of sample in test dataset: {len(X_test)}')

"""# Modeling

## Grid Search CV
"""

from sklearn.model_selection import GridSearchCV, train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.metrics import mean_squared_error
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import ShuffleSplit


X = df_encoded.drop('price', axis=1)
y = df_encoded['price']

cv = ShuffleSplit(n_splits=5, test_size=0.05, random_state=123)

algos = {
    'Linear Regression': {'model': LinearRegression(), 'params': {}},
    'Random Forest': {'model': RandomForestRegressor(), 'params': {'n_estimators': [50, 100, 150], 'max_depth': [None, 10, 20]}},
    'Gradient Boosting': {'model': GradientBoostingRegressor(), 'params': {'n_estimators': [50, 100, 150], 'learning_rate': [0.01, 0.1, 0.2]}}
}

scores = []

for algo_name, config in algos.items():
    gs = GridSearchCV(config['model'], config['params'], cv=cv, return_train_score=False)
    gs.fit(X, y)
    scores.append({
        'model': algo_name,
        'best_score': gs.best_score_,
        'best_params': gs.best_params_
    })

results_df = pd.DataFrame(scores, columns=['model', 'best_score', 'best_params'])

results_df

"""## Linear Regression"""

from sklearn.linear_model import LinearRegression

# Linear Regression
linear_reg_params = {}
linear_reg_model = LinearRegression(**linear_reg_params)
linear_reg_model.fit(X, y)
linear_reg_model.score(X_test, y_test)

"""## Random Forest"""

from sklearn.ensemble import RandomForestRegressor

# Random Forest
random_forest_params = {'max_depth': 20, 'n_estimators': 50}
random_forest_model = RandomForestRegressor(**random_forest_params)
random_forest_model.fit(X, y)
random_forest_model.score(X_test, y_test)

"""## Gradient Boosting"""

from sklearn.ensemble import GradientBoostingRegressor

# Gradient Boosting
gradient_boosting_params = {'learning_rate': 0.1, 'n_estimators': 100}
gradient_boosting_model = GradientBoostingRegressor(**gradient_boosting_params)
gradient_boosting_model.fit(X, y)
gradient_boosting_model.score(X_test, y_test)

"""## Evaluation the Model"""

from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score


linear_reg_predictions = linear_reg_model.predict(X)
random_forest_predictions = random_forest_model.predict(X)
gradient_boosting_predictions = gradient_boosting_model.predict(X)

mse_linear_reg = mean_squared_error(y, linear_reg_predictions)
mse_random_forest = mean_squared_error(y, random_forest_predictions)
mse_gradient_boosting = mean_squared_error(y, gradient_boosting_predictions)

mae_linear_reg = mean_absolute_error(y, linear_reg_predictions)
mae_random_forest = mean_absolute_error(y, random_forest_predictions)
mae_gradient_boosting = mean_absolute_error(y, gradient_boosting_predictions)

r2_linear_reg = r2_score(y, linear_reg_predictions)
r2_random_forest = r2_score(y, random_forest_predictions)
r2_gradient_boosting = r2_score(y, gradient_boosting_predictions)

results = pd.DataFrame({
    'Model': ['Linear Regression', 'Random Forest', 'Gradient Boosting'],
    'MSE': [mse_linear_reg, mse_random_forest, mse_gradient_boosting],
    'MAE': [mae_linear_reg, mae_random_forest, mae_gradient_boosting],
    'R-squared': [r2_linear_reg, r2_random_forest, r2_gradient_boosting]
})

results

import matplotlib.pyplot as plt
import seaborn as sns

plt.figure(figsize=(10, 6))

plt.subplot(2, 2, 1)
sns.barplot(x='Model', y='MSE', data=results)
plt.title('Mean Squared Error (MSE)')

plt.subplot(2, 2, 2)
sns.barplot(x='Model', y='MAE', data=results)
plt.title('Mean Absolute Error (MAE)')

plt.subplot(2, 2, 3)
sns.barplot(x='Model', y='R-squared', data=results)
plt.title('R-squared')

plt.tight_layout()
plt.show()

"""## Create a Prediction"""

pred_subset = X_test.iloc[5:10].copy()

pred_dict = {'y_true': y_test.iloc[5:10]}

model_dict = {
    'Linear Regression': linear_reg_model,
    'Random Forest': random_forest_model,
    'Gradient Boosting': gradient_boosting_model
}
for name, model in model_dict.items():
    pred_dict['pred_' + name] = model.predict(pred_subset).round(1)


prediction_df = pd.DataFrame(pred_dict)
prediction_df